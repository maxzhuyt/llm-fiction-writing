{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Idea Generation Exploration\n",
    "\n",
    "This notebook explores different approaches to generating story ideas using LLMs.\n",
    "\n",
    "**Approaches covered:**\n",
    "1. **Priming** - Have the model recall famous stories to enter \"fiction writer\" mode\n",
    "2. **Random Word Sampling** - Sample words from tokenizer vocabulary as creative seeds\n",
    "3. **Structured Random Elements** - Use LLM-driven randomness for story parameters\n",
    "4. **Constraint Mashup** - Combine incompatible constraints for creative tension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install openai tiktoken nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API key\n",
    "with open(\"credential\", \"r\") as f:\n",
    "    OPENROUTER_API_KEY = f.read().strip()\n",
    "\n",
    "# Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "# Model to use\n",
    "MODEL = \"anthropic/claude-sonnet-4\" # Using Sonnet for exploration (cheaper), switch to opus for final\n",
    "MODEL_OPUS = \"anthropic/claude-opus-4\"\n",
    "\n",
    "def call_llm(messages, model=MODEL, temperature=0.8, max_tokens=2000):\n",
    "    \"\"\"Call the LLM via OpenRouter.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 0: Priming with Famous Stories\n",
    "\n",
    "Before generating ideas, we prime the model by having it recall famous stories. This activates the \"fiction writer\" context in the model's latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 114 genres (pre-1970)\n",
      "Loaded 56 document types\n",
      "\n",
      "Sample genres: ['locked room mystery', 'regency romance', 'legal thriller', 'hard science fiction', 'picaresque', 'contemporary fiction', 'haunted house', 'essay', 'hardboiled', 'noir']\n"
     ]
    }
   ],
   "source": [
    "# Load genre list from genres.py\n",
    "from genres import ALL_GENRES, DOCUMENT_TYPES\n",
    "\n",
    "print(f\"Loaded {len(ALL_GENRES)} genres (pre-1970)\")\n",
    "print(f\"Loaded {len(DOCUMENT_TYPES)} document types\")\n",
    "print(f\"\\nSample genres: {random.sample(ALL_GENRES, 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(1900, 1991, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled genres: ['epic fantasy', 'spy fiction', 'whodunit', 'noir', 'historical mystery']\n",
      "Time period: 1960-2010\n",
      "\n",
      "==================================================\n",
      "\n",
      "Here are five exemplary stories from that era and their key craft elements:\n",
      "\n",
      "**Epic Fantasy: *The Lord of the Rings* (1954-1955) by J.R.R. Tolkien**\n",
      "Tolkien masterfully employed interwoven parallel narratives that gradually converged, creating mounting tension as readers tracked multiple storylines of increasing urgency. His technique of withholding Frodo and Sam's journey for entire chapters while following other characters created anxiety about their fate and made their eventual scenes feel more precious and hard-won.\n",
      "\n",
      "**Spy Fiction: *Tinker Tailor Soldier Spy* (1974) by John le Carré**\n",
      "Le Carré revolutionized the genre by structuring the novel as a methodical investigation rather than an action thriller, with George Smiley slowly peeling back layers of deception through quiet observation and psychological insight. The author created tension through information asymmetry—readers know a mole exists but must piece together clues alongside Smiley, making every conversation a potential minefield of hidden meaning.\n",
      "\n",
      "**Whodunit: *The Murder of Roger Ackroyd* (1926) by Agatha Christie**\n",
      "Christie's masterstroke was using an unreliable first-person narrator who conceals crucial information not through lies but through careful omission and misdirection. This technique allowed her to play completely fair with clues while still delivering one of mystery fiction's most shocking revelations about the narrator's own culpability.\n",
      "\n",
      "**Noir: *The Big Sleep* (1939) by Raymond Chandler**\n",
      "Chandler created atmosphere through his distinctive first-person voice that combined hard-boiled cynicism with unexpectedly poetic observations, making Philip Marlowe both tough and vulnerable. His technique of layering multiple interconnected crimes created a labyrinthine plot where solving one mystery only revealed deeper corruption, perfectly embodying noir's theme of pervasive moral decay.\n",
      "\n",
      "**Historical Mystery: *The Name of the Rose* (1980) by Umberto Eco**\n",
      "Eco brilliantly used the medieval monastery setting not just as backdrop but as a character itself, with the library's labyrinthine structure mirroring the complex mystery and the theological debates reflecting the investigation's deeper themes. His technique of embedding multiple layers of meaning—detective story, philosophical treatise, and historical allegory—created a rich, multi-dimensional reading experience that rewarded both casual and scholarly readers.\n"
     ]
    }
   ],
   "source": [
    "def prime_with_multi_genre_stories(n_genres=5):\n",
    "    \"\"\"\n",
    "    Sample n random genres and ask the model to recall famous stories from each.\n",
    "    This primes the model with diverse literary traditions before generation.\n",
    "    \"\"\"\n",
    "    # Sample random genres\n",
    "    sampled_genres = random.sample(ALL_GENRES, n_genres)\n",
    "    \n",
    "    # Randomly select a time period\n",
    "    start_year = random.randrange(1910, 1971, 10)\n",
    "    end_year = start_year + 50\n",
    "    time_period = f\"{start_year}-{end_year}\"\n",
    "    \n",
    "    genre_list = \"\\n\".join(f\"- {genre}\" for genre in sampled_genres)\n",
    "    \n",
    "    priming_prompt = f\"\"\"Before we begin generating story ideas, let's warm up your creative circuits.\n",
    "\n",
    "Here are 5 randomly selected literary genres:\n",
    "{genre_list}\n",
    "\n",
    "For each genre, recall ONE famous story (published roughly around {time_period}) that exemplifies it. \n",
    "For each story, explain in 1-2 sentences what narrative technique or structural choice made it memorable.\n",
    "Focus on specific craft elements: how did the author create tension, develop character, or subvert expectations?\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a literary analyst with deep knowledge of storytelling across genres and eras.\"},\n",
    "        {\"role\": \"user\", \"content\": priming_prompt}\n",
    "    ]\n",
    "    \n",
    "    result = call_llm(messages, temperature=0.7)\n",
    "    \n",
    "    return {\n",
    "        \"genres\": sampled_genres,\n",
    "        \"time_period\": time_period,\n",
    "        \"priming_text\": result\n",
    "    }\n",
    "\n",
    "# Test multi-genre priming\n",
    "multi_genre_prime = prime_with_multi_genre_stories()\n",
    "print(f\"Sampled genres: {multi_genre_prime['genres']}\")\n",
    "print(f\"Time period: {multi_genre_prime['time_period']}\")\n",
    "print(f\"\\n{'='*50}\\n\")\n",
    "print(multi_genre_prime['priming_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three enduring stories and what makes them unforgettable:\n",
      "\n",
      "## \"The Gift of the Magi\" by O. Henry\n",
      "\n",
      "**What makes it work:** The perfect ironic reversal. Both characters sacrifice their most precious possession to buy a gift that complements the other's treasure—rendering both gifts \"useless\" yet infinitely meaningful. This isn't just a clever twist; it's a structural mirror that reflects the story's theme. The narrative trick *becomes* the meaning: true love lies in the sacrifice itself, not the practical outcome.\n",
      "\n",
      "## \"Cinderella\" (various versions)\n",
      "\n",
      "**What makes it work:** The transformation fantasy taps into a universal psychological need—the belief that our true worth will eventually be recognized. But the story's genius lies in its specific imagery: glass slippers, pumpkin carriages, midnight deadlines. These concrete details make the impossible feel tangible. The story also follows a perfect rhythm of oppression → magic → triumph → test → reward that mirrors how we hope justice works in real life.\n",
      "\n",
      "## \"The Lottery\" by Shirley Jackson\n",
      "\n",
      "**What makes it work:** The masterful misdirection through normalcy. Jackson spends most of the story establishing a pleasant small-town atmosphere—children gathering stones, neighbors chatting, familiar rituals. The horror emerges not from the shocking ending alone, but from the slow realization that everyone knew what was coming. It forces readers to question their own assumptions about tradition, community, and complicity.\n",
      "\n",
      "Each story succeeds because its technique serves its deeper truth rather than just providing surface cleverness.\n"
     ]
    }
   ],
   "source": [
    "def prime_with_famous_stories(genre=None):\n",
    "    \"\"\"Have the model recall famous stories to prime it for fiction generation.\"\"\"\n",
    "    \n",
    "    # Randomly select a 5-year period between 1900 and 2020\n",
    "    start_year = random.randint(1900, 1990)  # 2015 so we can add 5 years\n",
    "    end_year = start_year + 30\n",
    "    time_period = f\"{start_year}-{end_year}\"\n",
    "    \n",
    "    genre_clause = f\" in the {genre} genre\" if genre else \"\"\n",
    "    \n",
    "    priming_prompt = f\"\"\"Before we begin generating story ideas, let's warm up your creative circuits.\n",
    "\n",
    "Think of 3 famous stories{genre_clause} published between {time_period}. \n",
    "For each one, identify what made it memorable. What narrative trick, thematic resonance, or structural choice made each story work?\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a literary analyst with knowledge of storytelling.\"},\n",
    "        {\"role\": \"user\", \"content\": priming_prompt}\n",
    "    ]\n",
    "    \n",
    "    return call_llm(messages, temperature=0.7)\n",
    "\n",
    "# Test priming\n",
    "priming_result = prime_with_famous_stories()\n",
    "print(priming_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre-specific priming\n",
    "priming_scifi = prime_with_famous_stories(genre=\"science fiction\")\n",
    "print(priming_scifi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 1: Random Word Sampling (Baseline)\n",
    "\n",
    "Sample 20 random words from the NLTK English dictionary (~235k words), then ask the LLM to generate a story idea from them.\n",
    "\n",
    "Unlike BPE tokenizers (tiktoken, etc.) which contain subword fragments, NLTK's words corpus contains complete English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 1: Random Word Sampling (Baseline)\n",
    "\n",
    "Sample 20 random words from the GPT-4 tokenizer vocabulary, **validated against NLTK dictionary**.\n",
    "\n",
    "This hybrid approach gives us:\n",
    "- **From tokenizer**: Words that are common enough to appear in modern text (not archaic/obscure)\n",
    "- **From dictionary**: Validation that these are complete real words (not subword fragments like `'geom'` or `'compreh'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 234377 words\n",
      "Extracted 10491 real words from tokenizer (validated against dictionary)\n",
      "Sample: ['funny', 'inner', 'eligible', 'melee', 'underscore', 'edge', 'capitol', 'paar', 'chain', 'saint', 'ethiopia', 'coupling', 'divers', 'shout', 'exchange', 'phill', 'compost', 'alberto', 'popcorn', 'protection']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import nltk\n",
    "\n",
    "# Download NLTK words corpus for dictionary validation\n",
    "nltk.download('words', quiet=True)\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "# Build a set of valid English words for fast lookup\n",
    "english_dict = set(w.lower() for w in nltk_words.words())\n",
    "print(f\"Dictionary size: {len(english_dict)} words\")\n",
    "\n",
    "# Load GPT-4 tokenizer (cl100k_base encoding)\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def get_real_words_from_tokenizer(encoding, max_id=110000, min_len=4, max_len=15):\n",
    "    \"\"\"\n",
    "    Extract tokens from LLM tokenizer, but only keep those that are \n",
    "    real English words (validated against dictionary).\n",
    "    \n",
    "    This gives us words that are:\n",
    "    1. Common enough to be in an LLM's vocabulary (actually used in text)\n",
    "    2. Complete real words (not subword fragments)\n",
    "    \"\"\"\n",
    "    real_words = []\n",
    "    for i in range(max_id):\n",
    "        try:\n",
    "            token = encoding.decode([i])\n",
    "            # Tokens with leading space are word boundaries\n",
    "            if token.startswith(\" \"):\n",
    "                word = token.strip().lower()\n",
    "                # Check: alphabetic, right length, AND in dictionary\n",
    "                if (word.isalpha() and \n",
    "                    min_len <= len(word) <= max_len and\n",
    "                    word in english_dict):\n",
    "                    real_words.append(word)\n",
    "        except:\n",
    "            continue\n",
    "    return list(set(real_words))\n",
    "\n",
    "vocab_words = get_real_words_from_tokenizer(enc, max_id=75000)\n",
    "print(f\"Extracted {len(vocab_words)} real words from tokenizer (validated against dictionary)\")\n",
    "print(f\"Sample: {random.sample(vocab_words, 20)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random words: ['nathan', 'screened', 'oracle', 'delaware', 'prosperous', 'welfare', 'conditioned', 'tour', 'aggressively', 'browse', 'petite', 'evil', 'myself', 'achievement', 'salon', 'shel', 'stated', 'former', 'commander', 'always']\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom words: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m idea_no_prime \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_idea_from_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(idea_no_prime)\n",
      "Cell \u001b[0;32mIn[86], line 34\u001b[0m, in \u001b[0;36mgenerate_idea_from_words\u001b[0;34m(words, priming_context)\u001b[0m\n\u001b[1;32m     30\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a creative writing expert skilled at finding unexpected story seeds.\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     32\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt})\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m, in \u001b[0;36mcall_llm\u001b[0;34m(messages, model, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_llm\u001b[39m(messages, model\u001b[38;5;241m=\u001b[39mMODEL, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM via OpenRouter.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 922\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/project/jevans/maxzhuyt/honest_llama_env/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def sample_random_words(n=20):\n",
    "    \"\"\"Sample n random words from vocabulary.\"\"\"\n",
    "    return random.sample(vocab_words, min(n, len(vocab_words)))\n",
    "\n",
    "\n",
    "def generate_idea_from_words(words, priming_context=None):\n",
    "    \"\"\"Generate a story idea using the given words as creative seeds.\"\"\"\n",
    "    \n",
    "    word_list = \", \".join(words)\n",
    "    \n",
    "    prompt = f\"\"\"Here are 20 randomly selected words:\n",
    "\n",
    "{word_list}\n",
    "\n",
    "Using at least 5 of these words as inspiration (not necessarily literally), generate a compelling story idea (3-4 sentences). \n",
    "Before you generate, think about: \n",
    "What is the core situation? What makes this story impossible to put down? \n",
    "What is the primary form this story should take? (such as personal letter, journal, interview transcript, bureaucratic report, diplomatic correspondence, research log, notebook, company memo, obituary, field notes, pamphlet, ad, telegram, etc.)\n",
    "Your response should include the story idea only. No intro, no outro. Be specific. Avoid generic tropes.\"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    \n",
    "    # Include priming context if provided\n",
    "    if priming_context:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"You are a creative writing expert who just analyzed what makes great stories work.\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": priming_context})\n",
    "    else:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"You are a creative writing expert skilled at finding unexpected story seeds.\"})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    return call_llm(messages, temperature=0.9)\n",
    "\n",
    "# Test: Generate without priming\n",
    "words = sample_random_words(20)\n",
    "print(f\"Random words: {words}\\n\")\n",
    "print(\"=\" * 50)\n",
    "idea_no_prime = generate_idea_from_words(words)\n",
    "print(idea_no_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random words: ['sitting', 'strange', 'upcoming', 'chat', 'alex', 'voter', 'introduce', 'colon', 'mutable', 'adapt', 'rencontre', 'protest', 'covid', 'ship', 'harassment', 'moscow', 'armed', 'find', 'note', 'vital']\n",
      "\n",
      "==================================================\n",
      "**Moscow Cultural Exchange Program - Incident Report #447-B**\n",
      "\n",
      "During a routine diplomatic chat to introduce visiting American voter registration specialist Alex Morrison to our Moscow counterparts, Morrison discovered a handwritten note in Cyrillic tucked inside a library book about pandemic protocols. The note detailed a strange rencontre (meeting) between Russian officials and an armed protest organizer, suggesting systematic harassment of opposition voters through deliberately spreading COVID misinformation in targeted districts. When Morrison attempted to photograph the evidence, the library's security system mysteriously malfunctioned, and now both Morrison and the Russian librarian who helped translate the note have gone missing, leaving only Morrison's partially encrypted research notes that suggest this conspiracy reaches vital government levels in both countries.\n"
     ]
    }
   ],
   "source": [
    "words = sample_random_words(20)\n",
    "print(f\"Random words: {words}\\n\")\n",
    "print(\"=\" * 50)\n",
    "idea_no_prime = generate_idea_from_words(words, priming_context=multi_genre_prime['priming_text'])\n",
    "print(idea_no_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result looks okay, but there are high-level echoes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 2: Structured Random Elements with LLM-Driven Randomness\n",
    "\n",
    "Instead of selecting from predetermined lists, we use the LLM itself to generate random elements with true creative variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_element(element_type, constraints=None):\n",
    "    \"\"\"\n",
    "    Use LLM to generate a random element with true creative variation.\n",
    "    The key insight: we ask for MULTIPLE options with specific variety requirements,\n",
    "    then randomly select one. This gives us LLM creativity + true randomness.\n",
    "    \"\"\"\n",
    "    \n",
    "    constraint_text = f\"\\nAdditional constraint: {constraints}\" if constraints else \"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"time_period\": f\"\"\"Generate 7 wildly different time periods for a story setting.\n",
    "Include:\n",
    "- At least one prehistoric or ancient\n",
    "- At least one that's a very specific year (not just \"the 1920s\" but \"1923\")\n",
    "- At least one far future\n",
    "- At least one that's oddly specific (\"the week after the 1906 San Francisco earthquake\")\n",
    "- Mix real historical periods with speculative ones{constraint_text}\n",
    "\n",
    "Return ONLY a JSON array of strings, nothing else.\"\"\",\n",
    "        \n",
    "        \"location\": f\"\"\"Generate 7 wildly different locations for a story setting.\n",
    "Include:\n",
    "- At least one that's a specific real place (not just \"a city\" but \"the basement of the Prague astronomical clock tower\")\n",
    "- At least one that's an unusual institutional setting (hospital morgue, patent office, lighthouse)\n",
    "- At least one natural environment with a twist\n",
    "- At least one that's in transit (ship, train, caravan)\n",
    "- Mix mundane and extraordinary{constraint_text}\n",
    "\n",
    "Return ONLY a JSON array of strings, nothing else.\"\"\",\n",
    "        \n",
    "        \"document_type\": f\"\"\"Generate 7 unusual document formats a story could take.\n",
    "Go beyond the obvious (letter, diary). Consider:\n",
    "- Official documents (incident report, autopsy, insurance claim, court transcript)\n",
    "- Institutional records (personnel file, surveillance log, maintenance checklist)\n",
    "- Personal artifacts (shopping list, margin notes in a book, voicemail transcript)\n",
    "- Technical documents (field observation notes, equipment manual, recipe)\n",
    "- Communication records (diplomatic cable, intercepted message, complaint form){constraint_text}\n",
    "\n",
    "Return ONLY a JSON array of strings, nothing else.\"\"\",\n",
    "        \n",
    "        \"narrative_constraint\": f\"\"\"Generate 7 unusual narrative constraints that could make a story interesting.\n",
    "Examples of the KIND of thing (don't use these exactly):\n",
    "- The narrator doesn't realize they're dead\n",
    "- Every paragraph must be exactly 50 words\n",
    "- The story is told in reverse chronological order\n",
    "- The narrator is an unreliable AI\n",
    "Be creative and specific.{constraint_text}\n",
    "\n",
    "Return ONLY a JSON array of strings, nothing else.\"\"\"\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a creative writing randomizer. Return ONLY valid JSON arrays.\"},\n",
    "        {\"role\": \"user\", \"content\": prompts[element_type]}\n",
    "    ]\n",
    "    \n",
    "    response = call_llm(messages, temperature=1.0, max_tokens=500)\n",
    "    \n",
    "    # Parse JSON response\n",
    "    try:\n",
    "        # Handle potential markdown code blocks\n",
    "        if \"```\" in response:\n",
    "            response = response.split(\"```\")[1]\n",
    "            if response.startswith(\"json\"):\n",
    "                response = response[4:]\n",
    "        options = json.loads(response.strip())\n",
    "        # Randomly select one\n",
    "        return random.choice(options)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse JSON: {response}\")\n",
    "        return response  # Return raw if parsing fails\n",
    "\n",
    "# Test each element type\n",
    "print(\"Time period:\", generate_random_element(\"time_period\"))\n",
    "print(\"Location:\", generate_random_element(\"location\"))\n",
    "print(\"Document type:\", generate_random_element(\"document_type\"))\n",
    "print(\"Narrative constraint:\", generate_random_element(\"narrative_constraint\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_story_idea(include_priming=True):\n",
    "    \"\"\"\n",
    "    Generate a story idea using structured random elements.\n",
    "    Each element is generated with LLM creativity + random selection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate random elements\n",
    "    print(\"Generating random elements...\")\n",
    "    time_period = generate_random_element(\"time_period\")\n",
    "    location = generate_random_element(\"location\")\n",
    "    document_type = generate_random_element(\"document_type\")\n",
    "    narrative_constraint = generate_random_element(\"narrative_constraint\")\n",
    "    \n",
    "    print(f\"\\nSelected elements:\")\n",
    "    print(f\"  Time: {time_period}\")\n",
    "    print(f\"  Location: {location}\")\n",
    "    print(f\"  Document: {document_type}\")\n",
    "    print(f\"  Constraint: {narrative_constraint}\")\n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "    \n",
    "    # Build the generation prompt\n",
    "    prompt = f\"\"\"Create a story idea using these specific parameters:\n",
    "\n",
    "**Time Period:** {time_period}\n",
    "**Location:** {location}\n",
    "**Document Format:** {document_type}\n",
    "**Narrative Constraint:** {narrative_constraint}\n",
    "\n",
    "Generate a compelling story concept that:\n",
    "1. Naturally incorporates ALL four elements\n",
    "2. Has a clear central tension or mystery\n",
    "3. Features a specific, interesting narrator voice\n",
    "4. Could only exist in this exact combination of parameters\n",
    "\n",
    "Provide:\n",
    "- **Premise** (3-4 sentences)\n",
    "- **Opening line** (the actual first line of the document)\n",
    "- **The hidden truth** (what the reader will discover that the narrator may not fully understand)\n",
    "\"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    \n",
    "    if include_priming:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"You are a master of found-document fiction, skilled at creating authentic-feeling artifacts that reveal larger stories.\"})\n",
    "        # Add a brief priming\n",
    "        messages.append({\"role\": \"user\", \"content\": \"Before we begin, what makes found-document fiction (epistolary novels, fake archives) so effective? One sentence.\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"Found-document fiction works because the gap between what the document says and what actually happened creates a space where the reader becomes an active detective, piecing together the truth from fragments the narrator never intended to reveal.\"})\n",
    "    else:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"You are a creative writing expert.\"})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    return call_llm(messages, temperature=0.85)\n",
    "\n",
    "# Generate a structured story idea\n",
    "structured_idea = generate_structured_story_idea()\n",
    "print(structured_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple ideas to see variety\n",
    "print(\"Generating 3 different structured story ideas...\\n\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"IDEA {i+1}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    idea = generate_structured_story_idea(include_priming=True)\n",
    "    print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 3: Constraint Mashup\n",
    "\n",
    "Generate story ideas by combining deliberately incompatible or surprising constraint pairs. The creative tension comes from resolving contradictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constraint_pair():\n",
    "    \"\"\"Generate a pair of constraints that seem incompatible.\"\"\"\n",
    "    \n",
    "    prompt = \"\"\"Generate 5 pairs of story constraints that seem incompatible or contradictory at first glance.\n",
    "\n",
    "Examples of what I mean:\n",
    "- \"A horror story\" + \"told entirely through wholesome family recipes\"\n",
    "- \"An epic spanning centuries\" + \"that takes place in real-time during a 3-minute phone call\"\n",
    "- \"A love story\" + \"where the lovers never meet\"\n",
    "\n",
    "The pairs should create CREATIVE TENSION - the story becomes interesting because the writer must resolve the apparent contradiction.\n",
    "\n",
    "Return as JSON array of objects with \"constraint_a\" and \"constraint_b\" keys.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a creative writing constraint generator. Return ONLY valid JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = call_llm(messages, temperature=1.0, max_tokens=800)\n",
    "    \n",
    "    try:\n",
    "        if \"```\" in response:\n",
    "            response = response.split(\"```\")[1]\n",
    "            if response.startswith(\"json\"):\n",
    "                response = response[4:]\n",
    "        pairs = json.loads(response.strip())\n",
    "        return random.choice(pairs)\n",
    "    except:\n",
    "        print(f\"Parse error: {response}\")\n",
    "        return {\"constraint_a\": \"a mystery\", \"constraint_b\": \"told in footnotes only\"}\n",
    "\n",
    "# Test\n",
    "pair = generate_constraint_pair()\n",
    "print(f\"Constraint A: {pair['constraint_a']}\")\n",
    "print(f\"Constraint B: {pair['constraint_b']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mashup_idea():\n",
    "    \"\"\"Generate a story idea from incompatible constraints.\"\"\"\n",
    "    \n",
    "    pair = generate_constraint_pair()\n",
    "    \n",
    "    print(f\"Constraints to reconcile:\")\n",
    "    print(f\"  A: {pair['constraint_a']}\")\n",
    "    print(f\"  B: {pair['constraint_b']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    prompt = f\"\"\"You must create a story idea that satisfies BOTH of these seemingly incompatible constraints:\n",
    "\n",
    "Constraint A: {pair['constraint_a']}\n",
    "Constraint B: {pair['constraint_b']}\n",
    "\n",
    "Your job is to find the elegant solution - the story concept where both constraints aren't just accommodated but actually STRENGTHEN each other.\n",
    "\n",
    "Provide:\n",
    "1. **The Resolution**: How do these constraints actually work together? (2-3 sentences)\n",
    "2. **The Story**: Premise, setting, central character (3-4 sentences)\n",
    "3. **Why It Works**: What does this combination reveal that neither constraint alone would? (1-2 sentences)\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a master of constrained writing, finding creative solutions where others see impossibility.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    return call_llm(messages, temperature=0.85)\n",
    "\n",
    "# Generate mashup idea\n",
    "mashup_idea = generate_mashup_idea()\n",
    "print(mashup_idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 4: Full Pipeline - Priming + Random + Structure\n",
    "\n",
    "Combine all approaches into a comprehensive story idea generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline_generate(use_opus=False):\n",
    "    \"\"\"\n",
    "    Full pipeline combining all approaches:\n",
    "    1. Prime with famous stories\n",
    "    2. Generate random word seeds\n",
    "    3. Generate structured elements\n",
    "    4. Synthesize into final idea\n",
    "    \"\"\"\n",
    "    \n",
    "    model = MODEL_OPUS if use_opus else MODEL\n",
    "    print(f\"Using model: {model}\\n\")\n",
    "    \n",
    "    # Step 1: Prime\n",
    "    print(\"Step 1: Priming with famous stories...\")\n",
    "    priming = prime_with_famous_stories()\n",
    "    print(\"[Priming complete]\\n\")\n",
    "    \n",
    "    # Step 2: Random words\n",
    "    print(\"Step 2: Sampling random words...\")\n",
    "    words = sample_random_words(10)  # Fewer words, more focused\n",
    "    print(f\"Words: {words}\\n\")\n",
    "    \n",
    "    # Step 3: Structured elements\n",
    "    print(\"Step 3: Generating structured elements...\")\n",
    "    time_period = generate_random_element(\"time_period\")\n",
    "    location = generate_random_element(\"location\")\n",
    "    document_type = generate_random_element(\"document_type\")\n",
    "    \n",
    "    print(f\"  Time: {time_period}\")\n",
    "    print(f\"  Location: {location}\")\n",
    "    print(f\"  Document: {document_type}\\n\")\n",
    "    \n",
    "    # Step 4: Synthesize\n",
    "    print(\"Step 4: Synthesizing final idea...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    synthesis_prompt = f\"\"\"You are generating a story idea. You have been given:\n",
    "\n",
    "**Random word seeds (use at least 3 as thematic inspiration):**\n",
    "{', '.join(words)}\n",
    "\n",
    "**Structural parameters:**\n",
    "- Time period: {time_period}\n",
    "- Location: {location}  \n",
    "- Document format: {document_type}\n",
    "\n",
    "Create a story idea that:\n",
    "1. Weaves in themes suggested by the random words\n",
    "2. Is set specifically in the given time and place\n",
    "3. Takes the form of the specified document type\n",
    "4. Has a compelling mystery or tension at its core\n",
    "5. Features a narrator whose voice feels authentic to the document type\n",
    "\n",
    "Provide:\n",
    "- **Logline** (one sentence pitch)\n",
    "- **Setup** (the situation, 3-4 sentences)\n",
    "- **The Document** (what is this artifact and why does it exist?)\n",
    "- **The Narrator** (who wrote this and what do they want?)\n",
    "- **The Hidden Layer** (what truth lurks beneath the surface?)\n",
    "- **Opening Lines** (the first 2-3 sentences of the actual story)\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a master storyteller who has just been analyzing what makes great fiction work.\"},\n",
    "        {\"role\": \"assistant\", \"content\": priming},  # Include priming as context\n",
    "        {\"role\": \"user\", \"content\": synthesis_prompt}\n",
    "    ]\n",
    "    \n",
    "    result = call_llm(messages, model=model, temperature=0.85, max_tokens=1500)\n",
    "    return result\n",
    "\n",
    "# Run full pipeline\n",
    "final_idea = full_pipeline_generate(use_opus=False)  # Set to True for final quality\n",
    "print(final_idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparison: Run All Approaches\n",
    "\n",
    "Generate one idea from each approach to compare quality and variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_approaches():\n",
    "    \"\"\"Run all approaches and display results for comparison.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Approach 1: Random words only (no priming)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"APPROACH 1: Random Words (Baseline)\")\n",
    "    print(\"=\"*70)\n",
    "    words = sample_random_words(20)\n",
    "    print(f\"Words: {words}\\n\")\n",
    "    results['random_words'] = generate_idea_from_words(words, priming_context=None)\n",
    "    print(results['random_words'])\n",
    "    \n",
    "    # Approach 2: Structured elements\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"APPROACH 2: Structured Random Elements\")\n",
    "    print(\"=\"*70)\n",
    "    results['structured'] = generate_structured_story_idea(include_priming=True)\n",
    "    print(results['structured'])\n",
    "    \n",
    "    # Approach 3: Constraint mashup\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"APPROACH 3: Constraint Mashup\")\n",
    "    print(\"=\"*70)\n",
    "    results['mashup'] = generate_mashup_idea()\n",
    "    print(results['mashup'])\n",
    "    \n",
    "    # Approach 4: Full pipeline\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"APPROACH 4: Full Pipeline (All Combined)\")\n",
    "    print(\"=\"*70)\n",
    "    results['full'] = full_pipeline_generate(use_opus=False)\n",
    "    print(results['full'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison (this will take a few minutes due to multiple API calls)\n",
    "# comparison_results = compare_approaches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using Opus 4.5 for Final Generation\n",
    "\n",
    "For production-quality ideas, use the full pipeline with Opus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a production-quality idea with Opus 4.5\n",
    "print(\"Generating with Claude Opus 4.5...\\n\")\n",
    "opus_idea = full_pipeline_generate(use_opus=True)\n",
    "print(opus_idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Utility: Batch Generation for Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_idea_batch(n=5, approach=\"structured\"):\n",
    "    \"\"\"Generate multiple ideas for human selection.\"\"\"\n",
    "    \n",
    "    ideas = []\n",
    "    for i in range(n):\n",
    "        print(f\"\\nGenerating idea {i+1}/{n}...\")\n",
    "        \n",
    "        if approach == \"structured\":\n",
    "            idea = generate_structured_story_idea(include_priming=True)\n",
    "        elif approach == \"mashup\":\n",
    "            idea = generate_mashup_idea()\n",
    "        elif approach == \"random_words\":\n",
    "            words = sample_random_words(20)\n",
    "            idea = f\"Words: {words}\\n\\n\" + generate_idea_from_words(words)\n",
    "        else:\n",
    "            idea = full_pipeline_generate()\n",
    "            \n",
    "        ideas.append(idea)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"IDEA {i+1}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(idea)\n",
    "    \n",
    "    return ideas\n",
    "\n",
    "# Generate a batch of ideas (uncomment to run)\n",
    "# batch = generate_idea_batch(n=3, approach=\"structured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Approach | Pros | Cons | Best For |\n",
    "|----------|------|------|----------|\n",
    "| **Random Words** | Maximum unpredictability, forces novel connections | Can produce incoherent results | Breaking creative blocks |\n",
    "| **Structured Elements** | Coherent, specific settings | May feel formulaic | Found-document fiction |\n",
    "| **Constraint Mashup** | Creative tension drives innovation | Requires more synthesis effort | Experimental fiction |\n",
    "| **Full Pipeline** | Combines all benefits, highest quality | Slower, more API calls | Production story generation |\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For exploration**: Use structured elements with `document_type` focus\n",
    "2. **For breaking blocks**: Use random word sampling\n",
    "3. **For final generation**: Use full pipeline with Opus 4.5\n",
    "4. **Key insight**: Priming with famous stories consistently improves output quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honest_llama_env",
   "language": "python",
   "name": "honest_llama_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
